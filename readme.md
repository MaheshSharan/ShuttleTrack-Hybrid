# üè∏ ShuttleTrack: Transformer-CNN Hybrid for Shuttlecock Detection and Trajectory Tracking

## üìå Project Objective
Design and implement a **novel AI system** for detecting and tracking shuttlecock motion in **badminton videos** with international-match-level accuracy, providing a **trajectory overlay** on the video output.

> üéØ This model generalizes to unseen badminton videos and aims to outperform traditional techniques like YOLO + Kalman or TrackNetV3.

---

## üöÄ Key Innovations
- **Enhanced CNN + Transformer Architecture:** Combines EfficientNetB3 backbone with a deeper TransformerEncoder (4 layers, 8 heads)
- **Temporal Fusion:** Multi-frame input for motion context
- **Median Background Subtraction:** Significantly improves small object detection over simple frame differencing
- **Hybrid Input Processing:** 6-channel input (3 RGB + 3 diff channels) for rich spatial and motion information
- **Advanced Training Techniques:** Dropout, gradient clipping, and optimized loss weights
- **Trajectory Overlay:** Broadcast-quality visual output with fading effects

---

## üîß Model Architecture

<img src="assets/architecture.svg" alt="ShuttleTrack Architecture" width="800"/>

### Model Improvements
The latest version includes significant improvements over the initial design:

- **Backbone:** Upgraded from ResNet18 to EfficientNetB3 (3-5√ó more powerful feature extraction)
- **Input Processing:** Enhanced with median-subtracted background differencing instead of simple frame diffs
- **Input Channels:** Expanded from 3 to 6 channels (RGB + diff) for better feature fusion
- **Transformer:** Increased from 2 to 4 layers with 8 attention heads (previously 4)
- **Regularization:** Added dropout (0.2) after CNN features to prevent overfitting
- **Training Stability:** 
  - Implemented gradient clipping at max_norm=1.0
  - Rebalanced loss weights (BCE√ó1.0 + MSE√ó5.0 + smooth√ó0.05)
- **Metrics:** Enhanced tracking of position accuracy, visibility F1, and pixel error thresholds
- **Visualization:** Improved trajectory rendering with fading effects

> üìà These improvements push the model toward 95-98% detection accuracy while maintaining real-time performance.

---

## ‚ö° How to Run (Step-by-Step)

### ‚öôÔ∏è Device (CPU/GPU) & Batch Size
- **Device selection:**
  - Open `config/shuttletrack.yaml` and set:
    ```yaml
    device: cuda  # for GPU (recommended if available)
    device: cpu   # for CPU (safe for low-end PCs)
    ```
  - If you set `cuda` but no GPU is available, the code will automatically fall back to CPU (no crash).
- **Batch size:**
  - In the same config file, adjust:
    ```yaml
    batch_size: 16  # decrease if you run out of memory, especially on CPU or low-end GPU
    ```
- **Tip:** For low-resource machines, use `device: cpu` and a small `batch_size` (e.g., 2 or 4).

### 1. **Install Requirements**
```bash
pip install -r requirements.txt
```

### 2. **Data Preprocessing**
Prepare your dataset in the `ShuttleCockFrameDataset` format, then run:
```bash
python scripts/preprocess.py
```
This preprocesses raw frames using our median background subtraction technique.

### 3. **Test Data Loader**
```bash
python test/test_dataset.py
```
This will display sample sequences with RGB frames and median-subtracted diffs side by side.

### 4. **Test Model Instantiation**
```bash
python test/test_model.py
```
Verifies the model architecture works correctly with 6-channel input.

### 5. **Train the Model**
```bash
python scripts/train.py
```
The training script includes detailed metrics, human-readable insights, and TensorBoard logging.

### 6. **Validation & Visualization**
- Evaluate metrics: see `utils/eval.py` for usage in your own scripts.
- Visualize predictions:
```bash
python scripts/visualize_predictions.py
```

### 7. **Inference on New Videos**
```bash
python scripts/infer.py --video path/to/video.mp4 --visualize
```
This will:
1. Preprocess the video with median background subtraction
2. Run inference using the trained model
3. Generate a CSV file with predictions
4. Create a visualization with trajectory overlay (if `--visualize` is specified)

### 8. **Interactive Streamlit App**
```bash
streamlit run streamlit_app.py
```
- Upload your trained model and a video.
- See real-time logs and the output video with trajectory overlay.

### 9. **Benchmarking**
Compare ShuttleTrack to baselines:
```bash
python utils/benchmark.py --ours predictions.csv --baseline baseline.csv --gt ground_truth.csv --output results/benchmark_report.md
```

---

## üì¶ Dataset Format
- **Input:** Badminton video sequences (30‚Äì60 FPS), frame-wise shuttlecock annotations (Frame,Visibility,X,Y)
- **Preprocessing:** RGB frames + median-subtracted diffs 
- **Output:** Shuttlecock positions and trajectory overlay

---

## üìä Performance Metrics
- **Detection Accuracy:** Visibility classification (F1 score)
- **Localization Precision:** Mean distance error in pixels
- **Within-K-Pixels:** Percentage of predictions within 5px and 10px of ground truth
- **Trajectory Smoothness:** Evaluated on visual quality and temporal consistency

---

## üìò References
- TrackNetV2/V3 (NCTU, 2019‚Äì2021)
- TrackFormer (ECCV 2022)
- EfficientNet (Google AI, 2019)
- Vision Transformers (Google/OpenAI)
- ShuttleSet Dataset (CoachAI)

---

## üì´ Contact
maheshsharan28@gmail.com